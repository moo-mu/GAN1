{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moo-mu/GAN1/blob/mid/multiple_residual_bs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zz5Ul0jXYV4X",
        "outputId": "7e7fbdb0-7ccc-47ff-84a4-21eea642f52d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "replace animals/testA/flickr_cat_000008.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "#google drive 마운트 후에 수집한 이미지 파일 unzip\n",
        "%cd /content/drive/MyDrive\n",
        "#!unzip -qq \"/content/drive/MyDrive/apple2banana.zip\" #apple2banana 케이스\n",
        "!unzip -qq \"/content/drive/MyDrive/animals.zip\" #cat2dog 케이스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHRg1SfL3GQ8"
      },
      "outputs": [],
      "source": [
        "#내가 설정한 경로가 맞나? 확인용.\n",
        "import pathlib\n",
        "#p_file = pathlib.Path('/content/drive/MyDrive/apple2banana/trainA/Screen Shot 2018-06-08 at 4.59.36 PM.png')\n",
        "p_file = pathlib.Path('/content/drive/MyDrive/animals/trainA/flickr_cat_000002.jpg')\n",
        "print(p_file.is_file())\n",
        "\n",
        "p_dir = pathlib.Path('/content/drive/MyDrive/animals/trainB')\n",
        "print(p_dir.is_dir())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hjlu5cqCYeZA"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "import imageio\n",
        "from skimage.transform import resize\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "\n",
        "class DataLoader():\n",
        "    def __init__(self, dataset_name, img_res=(128, 128)):\n",
        "        self.dataset_name = dataset_name\n",
        "        self.img_res = img_res\n",
        "\n",
        "    def load_data(self, domain, batch_size=1, is_testing=False):\n",
        "        data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n",
        "        path = glob('/content/drive/MyDrive/%s/%s/*' % (self.dataset_name, data_type))\n",
        "        \n",
        "\n",
        "        batch_images = np.random.choice(path, size=batch_size)\n",
        "\n",
        "        imgs = []\n",
        "        for img_path in batch_images:\n",
        "            img = self.imread(img_path)\n",
        "            if not is_testing:\n",
        "                img = resize(img, self.img_res)\n",
        "\n",
        "                if np.random.random() > 0.5:\n",
        "                    img = np.fliplr(img)\n",
        "            else:\n",
        "                img = resize(img, self.img_res)\n",
        "            imgs.append(img)\n",
        "\n",
        "        imgs = np.array(imgs)/127.5 - 1.\n",
        "\n",
        "        return imgs\n",
        "\n",
        "    def load_batch(self, batch_size=1, is_testing=False):\n",
        "        data_type = \"train\" if not is_testing else \"val\"\n",
        "        path_A = glob('/content/drive/MyDrive/%s/%sA/*' % (self.dataset_name, data_type))\n",
        "        path_B = glob('/content/drive/MyDrive/%s/%sB/*' % (self.dataset_name, data_type))\n",
        "\n",
        "        self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n",
        "        total_samples = self.n_batches * batch_size\n",
        "\n",
        "        path_A = np.random.choice(path_A, total_samples, replace=False)\n",
        "        path_B = np.random.choice(path_B, total_samples, replace=False)\n",
        "\n",
        "        for i in range(self.n_batches-1):\n",
        "            batch_A = path_A[i*batch_size:(i+1)*batch_size]\n",
        "            batch_B = path_B[i*batch_size:(i+1)*batch_size]\n",
        "            imgs_A, imgs_B = [], []\n",
        "            for img_A, img_B in zip(batch_A, batch_B):\n",
        "                img_A = self.imread(img_A)\n",
        "                img_B = self.imread(img_B)\n",
        "\n",
        "                img_A = resize(img_A, self.img_res)\n",
        "                img_B = resize(img_B, self.img_res)\n",
        "\n",
        "                if not is_testing and np.random.random() > 0.5:\n",
        "                        img_A = np.fliplr(img_A)\n",
        "                        img_B = np.fliplr(img_B)\n",
        "\n",
        "                imgs_A.append(img_A)\n",
        "                imgs_B.append(img_B)\n",
        "\n",
        "            imgs_A = np.array(imgs_A)/127.5 - 1.\n",
        "            imgs_B = np.array(imgs_B)/127.5 - 1.\n",
        "\n",
        "            yield imgs_A, imgs_B\n",
        "\n",
        "    def imread(self, path):\n",
        "        return imageio.imread(path, pilmode='RGB').astype(np.float64)\n",
        "    \n",
        "#print(glob('/content/drive/MyDrive/apple2orange/trainA/*'))\n",
        "#print(len('/content/drive/MyDrive/apple2orange/trainA/*'))\n",
        "\n",
        "#구글 드라이브에 파일이 빠짐없이 압축해제 되었는지 보려고 써봄. 개수가 잘 맞음.\n",
        "#countForFileNum = 0\n",
        "#for path in p_dir.iterdir():\n",
        "#    if path.is_file():\n",
        "#        countForFileNum += 1\n",
        "\n",
        "#print(countForFileNum)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTsJYzDKYlrN"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-addons==0.10\n",
        "from __future__ import print_function, division\n",
        "import scipy\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow_addons.layers import InstanceNormalization\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Add\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class CycleGAN():\n",
        "    def __init__(self):\n",
        "        self.img_rows = 128\n",
        "        self.img_cols = 128\n",
        "        self.channels = 3\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "\n",
        "\n",
        "        self.dataset_name = 'apple2banana'\n",
        "        #self.dataset_name = 'animals'\n",
        "        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n",
        "                                      img_res=(self.img_rows, self.img_cols))\n",
        "        \n",
        "        ##patch = int(self.img_rows / 2**4)\n",
        "        patch = int(self.img_rows / 2**6) \n",
        "        self.disc_patch = (patch, patch, 1)\n",
        "\n",
        "        #self.gf = 32\n",
        "        self.gf = 64\n",
        "        self.df = 64\n",
        "\n",
        "        #self.lambda_cycle = 10.0      \n",
        "        #self.lambda_id = 0.9 * self.lambda_cycle    \n",
        "        self.lambda_cycle = 3.0       \n",
        "        self.lambda_id = 0.9 * self.lambda_cycle    \n",
        "        #self.lambda_cycle = 0                   # cycle-consistency loss, identity loss 무시 \n",
        "        #self.lambda_id = 0 #0.9 * self.lambda_cycle\n",
        "\n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "        \n",
        "        self.d_A = self.build_discriminator()\n",
        "        self.d_B = self.build_discriminator()\n",
        "        self.d_A.compile(loss='mse',\n",
        "                         optimizer=optimizer,\n",
        "                         metrics=['accuracy'])\n",
        "        self.d_B.compile(loss='mse',\n",
        "                         optimizer=optimizer,\n",
        "                         metrics=['accuracy'])\n",
        "\n",
        "        self.g_AB = self.build_generator()\n",
        "        self.g_BA = self.build_generator()\n",
        "\n",
        "        img_A = Input(shape=self.img_shape)\n",
        "        img_B = Input(shape=self.img_shape)\n",
        "\n",
        "        fake_B = self.g_AB(img_A)\n",
        "        fake_A = self.g_BA(img_B)\n",
        "\n",
        "        reconstr_A = self.g_BA(fake_B)\n",
        "        reconstr_B = self.g_AB(fake_A)\n",
        "\n",
        "        img_A_id = self.g_BA(img_A)\n",
        "        img_B_id = self.g_AB(img_B)\n",
        "\n",
        "        self.d_A.trainable = False\n",
        "        self.d_B.trainable = False\n",
        "\n",
        "        valid_A = self.d_A(fake_A)\n",
        "        valid_B = self.d_B(fake_B)\n",
        "\n",
        "        self.combined = Model(inputs=[img_A, img_B],\n",
        "                              outputs=[valid_A, valid_B,\n",
        "                                       reconstr_A, reconstr_B,\n",
        "                                       img_A_id, img_B_id])\n",
        "        self.combined.compile(loss=['mse', 'mse',\n",
        "                                    'mae', 'mae',\n",
        "                                    'mae', 'mae'],\n",
        "                              loss_weights=[1, 1,\n",
        "                                            self.lambda_cycle, self.lambda_cycle,\n",
        "                                            self.lambda_id, self.lambda_id],\n",
        "                              optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1Som6tIYxmw"
      },
      "outputs": [],
      "source": [
        "class CycleGAN(CycleGAN):\n",
        "      @staticmethod\n",
        "      def conv2d(layer_input, filters, f_size=4, normalization=True):\n",
        "        d = Conv2D(filters, kernel_size=f_size,\n",
        "                   strides=2, padding='same')(layer_input)\n",
        "        d = LeakyReLU(alpha=0.2)(d)\n",
        "        if normalization:\n",
        "            d = InstanceNormalization()(d)\n",
        "        return d\n",
        "      \n",
        "      @staticmethod\n",
        "      def deconv2d(layer_input, filters, f_size=4, dropout_rate=0): #skip connection 삭제, deconv2d method 말고 따로 구현 예정\n",
        "            u = UpSampling2D(size=2)(layer_input)\n",
        "            u = Conv2D(filters, kernel_size=f_size, strides=1,\n",
        "                       padding='same', activation='relu')(u)\n",
        "            \n",
        "            if dropout_rate:\n",
        "                u = Dropout(dropout_rate)(u)\n",
        "            u = InstanceNormalization()(u)           \n",
        "            return u\n",
        "      #residual block 추가\n",
        "      @staticmethod\n",
        "      def residual_block(x, filters_in, filters_out, k_size):\n",
        "            shortcut = x\n",
        "            x = Conv2D(filters_in, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = LeakyReLU()(x)\n",
        "            \n",
        "            x = Conv2D(filters_in, kernel_size=(k_size, k_size), strides=(1, 1), padding=\"same\")(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = LeakyReLU()(x)    \n",
        "            \n",
        "            x = Conv2D(filters_out, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            \n",
        "            shortcut_channel = shortcut.shape.as_list()[-1]\n",
        "            \n",
        "            if shortcut_channel != filters_out:\n",
        "                shortcut = Conv2D(filters_out, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(shortcut)\n",
        "                \n",
        "            x = Add()([x, shortcut])\n",
        "            #x = Concatenate()([x, shortcut])\n",
        "            return LeakyReLU(alpha=0.2)(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#residual block 적용한 generator구조 encoder decoder에 총 5개의 residual block 추가 및 residual block의 결과 skip connect 함, original cycle_gan 의 경우 depth=9의 단일 residual block 사용\n",
        "#residual block의 kernel_size = 3 나머지 convolution, deconovolution 의 kerner_size = 4\n",
        "class CycleGAN(CycleGAN):\n",
        "    def build_generator(self):\n",
        "        d0 = Input(shape=self.img_shape)\n",
        "        print(\"d0shape: \",d0.shape)\n",
        "        d1 = self.conv2d(d0, self.gf) \n",
        "        print(\"d1shape: \",d1.shape)\n",
        "        d2 = self.conv2d(d1, self.gf * 2)\n",
        "        print(\"d2shape: \",d2.shape)\n",
        "        r1 = self.residual_block(d2, self.gf*2, self.gf*2, 3)\n",
        "        print(\"r1shape: \",r1.shape)\n",
        "\n",
        "        d3 = self.conv2d(r1, self.gf * 4)\n",
        "        print(\"d3shape: \",d3.shape)\n",
        "        r2 = self.residual_block(d3, self.gf*4, self.gf*4, 3)\n",
        "        print(\"r2shape: \",r2.shape)\n",
        "\n",
        "        d4 = self.conv2d(r2, self.gf * 8)\n",
        "        print(\"d4shape: \",d4.shape)\n",
        "        r3 = self.residual_block(d4, self.gf*8, self.gf*8, 3)\n",
        "        print(\"r3shape: \",r3.shape)\n",
        "        #downsampling 부분 끝\n",
        "\n",
        "        u1 = self.deconv2d(r3, self.gf * 4)\n",
        "        print(\"u1shape: \",u1.shape)\n",
        "        u1 = Concatenate()([u1, r2])\n",
        "        print(\"u1shape: \",u1.shape)\n",
        "        r4 = self.residual_block(u1, self.gf*4, self.gf*4, 3)\n",
        "        print(\"r4shape: \",r4.shape)\n",
        "\n",
        "        u2 = self.deconv2d(r4, self.gf * 2)\n",
        "        print(\"u2shape: \",u2.shape) \n",
        "        u2 = Concatenate()([u2, r1])\n",
        "        print(\"u2shape: \",u2.shape) \n",
        "        r5 = self.residual_block(u2, self.gf*2, self.gf*2, 3)\n",
        "        print(\"r5shape: \",r5.shape)\n",
        "        u3 = self.deconv2d(r5, self.gf)\n",
        "        print(\"u3shape: \",u3.shape)\n",
        "        \n",
        "\n",
        "        u4 = UpSampling2D(size=2)(u3) \n",
        "        \n",
        "        output_img = Conv2D(self.channels, kernel_size=4,\n",
        "                            strides=1, padding='same', activation='tanh')(u4)\n",
        "        print(output_img.shape)\n",
        "\n",
        "        return Model(d0, output_img)"
      ],
      "metadata": {
        "id": "a4P0GzlJFtKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xawpN_SBX2AN"
      },
      "outputs": [],
      "source": [
        "##dilated convoluttion 적용. dropout rate, kernel_size, validity 부분 점검 필요\n",
        "class CycleGAN(CycleGAN):\n",
        "    def build_discriminator(self):\n",
        "      img = Input(shape=self.img_shape) #(128,128)\n",
        "\n",
        "      d1 = self.conv2d(img, self.df*2, normalization=False) #(64,64,128)\n",
        "      #print(\"d1shape: \",d1.shape)\n",
        "      d2 = self.conv2d(d1, self.df * 4) #(32,32,256)\n",
        "      #print(\"d2shape: \",d2.shape)\n",
        "      d3 = self.conv2d(d2, self.df * 8) #(16,16,512)\n",
        "      #print(\"d3shape: \",d3.shape)\n",
        "      d4 = self.conv2d(d3, self.df * 8) #(8,8,512)\n",
        "      #print(\"d4shape: \",d4.shape)\n",
        "\n",
        "      dil1 = Conv2D(self.df * 8, kernel_size=4, strides=1, padding='same', dilation_rate=2)(d4)\n",
        "      dil1 = LeakyReLU(alpha=0.2)(dil1)\n",
        "      dil1 = InstanceNormalization()(dil1)\n",
        "\n",
        "      dil2 = Conv2D(self.df * 8, kernel_size=4, strides=1, padding='same', dilation_rate=4)(dil1)\n",
        "      dil2 = LeakyReLU(alpha=0.2)(dil2)\n",
        "      dil2 = InstanceNormalization()(dil2)\n",
        "\n",
        "      dil3 = Conv2D(self.df * 8, kernel_size=4, strides=1, padding='same', dilation_rate=8)(dil2)\n",
        "      dil3 = LeakyReLU(alpha=0.2)(dil3)\n",
        "      dil3 = InstanceNormalization()(dil3)\n",
        "      \n",
        "      merge = Concatenate()([dil3, d4])\n",
        "      \n",
        "      d5 = Conv2D(self.df * 8, kernel_size=4, strides=2, padding='same')(merge)\n",
        "      d5 = LeakyReLU(alpha=0.2)(d5)\n",
        "      d5 = InstanceNormalization()(d5)\n",
        "\n",
        "      validity = Conv2D(1, kernel_size=4, strides=2, padding='same')(d5)\n",
        "      print(\"validityshape: \",validity.shape)\n",
        "\n",
        "      return Model(img, validity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZow6dssZIdo"
      },
      "outputs": [],
      "source": [
        "class CycleGAN(CycleGAN):\n",
        "      def sample_images(self, epoch, batch_i):\n",
        "        r, c = 2, 3\n",
        "\n",
        "        imgs_A = self.data_loader.load_data(domain=\"A\", batch_size=1, is_testing=True)\n",
        "        imgs_B = self.data_loader.load_data(domain=\"B\", batch_size=1, is_testing=True)\n",
        "        \n",
        "        fake_B = self.g_AB.predict(imgs_A)\n",
        "        fake_A = self.g_BA.predict(imgs_B)\n",
        "\n",
        "        reconstr_A = self.g_BA.predict(fake_B)\n",
        "        reconstr_B = self.g_AB.predict(fake_A)\n",
        "\n",
        "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n",
        "\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        titles = ['Original', 'Translated', 'Reconstructed']\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt])\n",
        "                axs[i, j].set_title(titles[j])\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig('/content/drive/MyDrive/images3/%s/%d_%d.png' % (self.dataset_name, epoch, batch_i))\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Cywl7CgZKdq"
      },
      "outputs": [],
      "source": [
        "class CycleGAN(CycleGAN):\n",
        "      def train(self, epochs, batch_size=1, sample_interval=50):\n",
        "        valid = np.ones((batch_size,) + self.disc_patch)\n",
        "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
        "\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n",
        "\n",
        "                fake_B = self.g_AB.predict(imgs_A)\n",
        "                fake_A = self.g_BA.predict(imgs_B)\n",
        "\n",
        "                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n",
        "                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n",
        "                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
        "\n",
        "                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n",
        "                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n",
        "                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
        "\n",
        "                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
        "\n",
        "\n",
        "                g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n",
        "                                                      [valid, valid,\n",
        "                                                       imgs_A, imgs_B,\n",
        "                                                       imgs_A, imgs_B])\n",
        "\n",
        "                if batch_i % sample_interval == 0:\n",
        "                    self.sample_images(epoch, batch_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSjZ-8axZPKz"
      },
      "outputs": [],
      "source": [
        "cycle_gan = CycleGAN()\n",
        "cycle_gan.train(epochs=100, batch_size=64, sample_interval=10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "multiple residual bs",
      "provenance": [],
      "mount_file_id": "17awv-Pvyqmlo_DHrghOufKhhwAZBuMNV",
      "authorship_tag": "ABX9TyMgODGMPJRiQt4n2YB0Q/jf",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}