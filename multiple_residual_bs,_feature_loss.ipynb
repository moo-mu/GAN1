{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moo-mu/GAN1/blob/mid/multiple_residual_bs%2C_feature_loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zz5Ul0jXYV4X",
        "outputId": "4a89b037-1740-41ab-8496-c2ce2383ed5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "replace animals/testA/flickr_cat_000008.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "#google drive 마운트 후에 수집한 이미지 파일 unzip\n",
        "%cd /content/drive/MyDrive\n",
        "#!unzip -qq \"/content/drive/MyDrive/apple2banana.zip\" #apple2banana 케이스\n",
        "!unzip -qq \"/content/drive/MyDrive/animals.zip\" #cat2dog 케이스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHRg1SfL3GQ8",
        "outputId": "17f4cc77-a6bd-4864-bda4-2b5c821d68bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "#내가 설정한 경로가 맞나? 확인용.\n",
        "import pathlib\n",
        "#p_file = pathlib.Path('/content/drive/MyDrive/apple2banana/trainA/Screen Shot 2018-06-08 at 4.59.36 PM.png')\n",
        "p_file = pathlib.Path('/content/drive/MyDrive/animals/trainA/flickr_cat_000002.jpg')\n",
        "print(p_file.is_file())\n",
        "\n",
        "p_dir = pathlib.Path('/content/drive/MyDrive/animals/trainB')\n",
        "print(p_dir.is_dir())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hjlu5cqCYeZA"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "import imageio\n",
        "from skimage.transform import resize\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "\n",
        "class DataLoader():\n",
        "    def __init__(self, dataset_name, img_res=(128, 128)):\n",
        "        self.dataset_name = dataset_name\n",
        "        self.img_res = img_res\n",
        "\n",
        "    def load_data(self, domain, batch_size=1, is_testing=False):\n",
        "        data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n",
        "        path = glob('/content/drive/MyDrive/%s/%s/*' % (self.dataset_name, data_type))\n",
        "        \n",
        "\n",
        "        batch_images = np.random.choice(path, size=batch_size)\n",
        "\n",
        "        imgs = []\n",
        "        for img_path in batch_images:\n",
        "            img = self.imread(img_path)\n",
        "            if not is_testing:\n",
        "                img = resize(img, self.img_res)\n",
        "\n",
        "                if np.random.random() > 0.5:\n",
        "                    img = np.fliplr(img)\n",
        "            else:\n",
        "                img = resize(img, self.img_res)\n",
        "            imgs.append(img)\n",
        "\n",
        "        imgs = np.array(imgs)/127.5 - 1.\n",
        "\n",
        "        return imgs\n",
        "\n",
        "    def load_batch(self, batch_size=1, is_testing=False):\n",
        "        data_type = \"train\" if not is_testing else \"val\"\n",
        "        path_A = glob('/content/drive/MyDrive/%s/%sA/*' % (self.dataset_name, data_type))\n",
        "        path_B = glob('/content/drive/MyDrive/%s/%sB/*' % (self.dataset_name, data_type))\n",
        "\n",
        "        self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n",
        "        total_samples = self.n_batches * batch_size\n",
        "\n",
        "        path_A = np.random.choice(path_A, total_samples, replace=False)\n",
        "        path_B = np.random.choice(path_B, total_samples, replace=False)\n",
        "\n",
        "        for i in range(self.n_batches-1):\n",
        "            batch_A = path_A[i*batch_size:(i+1)*batch_size]\n",
        "            batch_B = path_B[i*batch_size:(i+1)*batch_size]\n",
        "            imgs_A, imgs_B = [], []\n",
        "            for img_A, img_B in zip(batch_A, batch_B):\n",
        "                img_A = self.imread(img_A)\n",
        "                img_B = self.imread(img_B)\n",
        "\n",
        "                img_A = resize(img_A, self.img_res)\n",
        "                img_B = resize(img_B, self.img_res)\n",
        "\n",
        "                if not is_testing and np.random.random() > 0.5:\n",
        "                        img_A = np.fliplr(img_A)\n",
        "                        img_B = np.fliplr(img_B)\n",
        "\n",
        "                imgs_A.append(img_A)\n",
        "                imgs_B.append(img_B)\n",
        "\n",
        "            imgs_A = np.array(imgs_A)/127.5 - 1.\n",
        "            imgs_B = np.array(imgs_B)/127.5 - 1.\n",
        "\n",
        "            yield imgs_A, imgs_B\n",
        "\n",
        "    def imread(self, path):\n",
        "        return imageio.imread(path, pilmode='RGB').astype(np.float64)\n",
        "    \n",
        "#print(glob('/content/drive/MyDrive/apple2orange/trainA/*'))\n",
        "#print(len('/content/drive/MyDrive/apple2orange/trainA/*'))\n",
        "\n",
        "#구글 드라이브에 파일이 빠짐없이 압축해제 되었는지 보려고 써봄. 개수가 잘 맞음.\n",
        "#countForFileNum = 0\n",
        "#for path in p_dir.iterdir():\n",
        "#    if path.is_file():\n",
        "#        countForFileNum += 1\n",
        "\n",
        "#print(countForFileNum)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTsJYzDKYlrN",
        "outputId": "01e0c90a-f8d1-490f-b7fb-0765771f6b30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-addons==0.10 in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons==0.10) (2.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons==0.10\n",
        "from __future__ import print_function, division\n",
        "import scipy\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow_addons.layers import InstanceNormalization\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Add\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class CycleGAN():\n",
        "    def __init__(self):\n",
        "        self.img_rows = 128\n",
        "        self.img_cols = 128\n",
        "        self.channels = 3\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "\n",
        "\n",
        "        self.dataset_name = 'apple2banana'\n",
        "        #self.dataset_name = 'animals'\n",
        "        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n",
        "                                      img_res=(self.img_rows, self.img_cols))\n",
        "        \n",
        "        ##patch = int(self.img_rows / 2**4)\n",
        "        patch = int(self.img_rows / 2**6) \n",
        "        self.disc_patch = (patch, patch, 1)\n",
        "\n",
        "        #self.gf = 32\n",
        "        self.gf = 64\n",
        "        self.df = 64\n",
        "\n",
        "        #self.lambda_cycle = 10.0      \n",
        "        #self.lambda_id = 0.9 * self.lambda_cycle    \n",
        "        self.lambda_cycle = 3.0       \n",
        "        self.lambda_id = 0.9 * self.lambda_cycle    \n",
        "        #self.lambda_cycle = 0                   # cycle-consistency loss, identity loss 무시 \n",
        "        #self.lambda_id = 0 #0.9 * self.lambda_cycle\n",
        "\n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "        \n",
        "        self.d_A = self.build_discriminator()\n",
        "        self.d_B = self.build_discriminator()\n",
        "        self.d_A.compile(loss='mse',\n",
        "                         optimizer=optimizer,\n",
        "                         metrics=['accuracy'])\n",
        "        self.d_B.compile(loss='mse',\n",
        "                         optimizer=optimizer,\n",
        "                         metrics=['accuracy'])\n",
        "\n",
        "        self.g_AB = self.build_generator()\n",
        "        self.g_BA = self.build_generator()\n",
        "\n",
        "        img_A = Input(shape=self.img_shape)\n",
        "        img_B = Input(shape=self.img_shape)\n",
        "\n",
        "        fake_B = self.g_AB(img_A)\n",
        "        fake_A = self.g_BA(img_B)\n",
        "\n",
        "        reconstr_A = self.g_BA(fake_B)\n",
        "        reconstr_B = self.g_AB(fake_A)\n",
        "\n",
        "        img_A_id = self.g_BA(img_A)\n",
        "        img_B_id = self.g_AB(img_B)\n",
        "\n",
        "        self.d_A.trainable = False\n",
        "        self.d_B.trainable = False\n",
        "\n",
        "        valid_A = self.d_A(fake_A)\n",
        "        valid_B = self.d_B(fake_B)\n",
        "\n",
        "        self.combined = Model(inputs=[img_A, img_B],\n",
        "                              outputs=[valid_A, valid_B,\n",
        "                                       reconstr_A, reconstr_B,\n",
        "                                       img_A_id, img_B_id])\n",
        "        self.combined.compile(loss=['mse', 'mse',\n",
        "                                    'mae', 'mae',\n",
        "                                    'mae', 'mae'],\n",
        "                              loss_weights=[1, 1,\n",
        "                                            self.lambda_cycle, self.lambda_cycle,\n",
        "                                            self.lambda_id, self.lambda_id],\n",
        "                              optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1Som6tIYxmw"
      },
      "outputs": [],
      "source": [
        "class CycleGAN(CycleGAN):\n",
        "      @staticmethod\n",
        "      def conv2d(layer_input, filters, f_size=4, normalization=True):\n",
        "        d = Conv2D(filters, kernel_size=f_size,\n",
        "                   strides=2, padding='same')(layer_input)\n",
        "        d = LeakyReLU(alpha=0.2)(d)\n",
        "        if normalization:\n",
        "            d = InstanceNormalization()(d)\n",
        "        return d\n",
        "      \n",
        "      @staticmethod\n",
        "      def deconv2d(layer_input, filters, f_size=4, dropout_rate=0): #skip connection 삭제, deconv2d method 말고 따로 구현 예정\n",
        "            u = UpSampling2D(size=2)(layer_input)\n",
        "            u = Conv2D(filters, kernel_size=f_size, strides=1,\n",
        "                       padding='same', activation='relu')(u)\n",
        "            \n",
        "            if dropout_rate:\n",
        "                u = Dropout(dropout_rate)(u)\n",
        "            u = InstanceNormalization()(u)           \n",
        "            return u\n",
        "      #residual block 추가\n",
        "      @staticmethod\n",
        "      def residual_block(x, filters_in, filters_out, k_size):\n",
        "            shortcut = x\n",
        "            x = Conv2D(filters_in, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = LeakyReLU()(x)\n",
        "            \n",
        "            x = Conv2D(filters_in, kernel_size=(k_size, k_size), strides=(1, 1), padding=\"same\")(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = LeakyReLU()(x)    \n",
        "            \n",
        "            x = Conv2D(filters_out, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            \n",
        "            shortcut_channel = shortcut.shape.as_list()[-1]\n",
        "            \n",
        "            if shortcut_channel != filters_out:\n",
        "                shortcut = Conv2D(filters_out, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(shortcut)\n",
        "                \n",
        "            x = Add()([x, shortcut])\n",
        "            #x = Concatenate()([x, shortcut])\n",
        "            return LeakyReLU(alpha=0.2)(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#residual block 적용한 generator구조 encoder decoder에 총 5개의 residual block 추가 및 residual block의 결과 skip connect 함, original cycle_gan 의 경우 depth=9의 단일 residual block 사용\n",
        "#residual block의 kernel_size = 3 나머지 convolution, deconovolution 의 kerner_size = 4\n",
        "class CycleGAN(CycleGAN):\n",
        "    def build_generator(self):\n",
        "        d0 = Input(shape=self.img_shape)\n",
        "        print(\"d0shape: \",d0.shape)\n",
        "        d1 = self.conv2d(d0, self.gf) \n",
        "        print(\"d1shape: \",d1.shape)\n",
        "        d2 = self.conv2d(d1, self.gf * 2)\n",
        "        print(\"d2shape: \",d2.shape)\n",
        "        r1 = self.residual_block(d2, self.gf*2, self.gf*2, 3)\n",
        "        print(\"r1shape: \",r1.shape)\n",
        "\n",
        "        d3 = self.conv2d(r1, self.gf * 4)\n",
        "        print(\"d3shape: \",d3.shape)\n",
        "        r2 = self.residual_block(d3, self.gf*4, self.gf*4, 3)\n",
        "        print(\"r2shape: \",r2.shape)\n",
        "\n",
        "        d4 = self.conv2d(r2, self.gf * 8)\n",
        "        print(\"d4shape: \",d4.shape)\n",
        "        r3 = self.residual_block(d4, self.gf*8, self.gf*8, 3)\n",
        "        print(\"r3shape: \",r3.shape)\n",
        "        #downsampling 부분 끝\n",
        "\n",
        "        u1 = self.deconv2d(r3, self.gf * 4)\n",
        "        print(\"u1shape: \",u1.shape)\n",
        "        u1 = Concatenate()([u1, r2])\n",
        "        print(\"u1shape: \",u1.shape)\n",
        "        r4 = self.residual_block(u1, self.gf*4, self.gf*4, 3)\n",
        "        print(\"r4shape: \",r4.shape)\n",
        "\n",
        "        u2 = self.deconv2d(r4, self.gf * 2)\n",
        "        print(\"u2shape: \",u2.shape) \n",
        "        u2 = Concatenate()([u2, r1])\n",
        "        print(\"u2shape: \",u2.shape) \n",
        "        r5 = self.residual_block(u2, self.gf*2, self.gf*2, 3)\n",
        "        print(\"r5shape: \",r5.shape)\n",
        "        u3 = self.deconv2d(r5, self.gf)\n",
        "        print(\"u3shape: \",u3.shape)\n",
        "        \n",
        "\n",
        "        u4 = UpSampling2D(size=2)(u3) \n",
        "        \n",
        "        output_img = Conv2D(self.channels, kernel_size=4,\n",
        "                            strides=1, padding='same', activation='tanh')(u4)\n",
        "        print(output_img.shape)\n",
        "\n",
        "        return Model(d0, output_img)"
      ],
      "metadata": {
        "id": "a4P0GzlJFtKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xawpN_SBX2AN"
      },
      "outputs": [],
      "source": [
        "##dilated convoluttion 적용. dropout rate, kernel_size, validity 부분 점검 필요\n",
        "class CycleGAN(CycleGAN):\n",
        "    def build_discriminator(self):\n",
        "      img = Input(shape=self.img_shape) #(128,128)\n",
        "\n",
        "      d1 = self.conv2d(img, self.df*2, normalization=False) #(64,64,128)\n",
        "      #print(\"d1shape: \",d1.shape)\n",
        "      d2 = self.conv2d(d1, self.df * 4) #(32,32,256)\n",
        "      #print(\"d2shape: \",d2.shape)\n",
        "      d3 = self.conv2d(d2, self.df * 8) #(16,16,512)\n",
        "      #print(\"d3shape: \",d3.shape)\n",
        "      d4 = self.conv2d(d3, self.df * 8) #(8,8,512)\n",
        "      #print(\"d4shape: \",d4.shape)\n",
        "\n",
        "      dil1 = Conv2D(self.df * 8, kernel_size=4, strides=1, padding='same', dilation_rate=2)(d4)\n",
        "      dil1 = LeakyReLU(alpha=0.2)(dil1)\n",
        "      dil1 = InstanceNormalization()(dil1)\n",
        "\n",
        "      dil2 = Conv2D(self.df * 8, kernel_size=4, strides=1, padding='same', dilation_rate=4)(dil1)\n",
        "      dil2 = LeakyReLU(alpha=0.2)(dil2)\n",
        "      dil2 = InstanceNormalization()(dil2)\n",
        "\n",
        "      dil3 = Conv2D(self.df * 8, kernel_size=4, strides=1, padding='same', dilation_rate=8)(dil2)\n",
        "      dil3 = LeakyReLU(alpha=0.2)(dil3)\n",
        "      dil3 = InstanceNormalization()(dil3)\n",
        "      \n",
        "      merge = Concatenate()([dil3, d4])\n",
        "      \n",
        "      d5 = Conv2D(self.df * 8, kernel_size=4, strides=2, padding='same')(merge)\n",
        "      d5 = LeakyReLU(alpha=0.2)(d5)\n",
        "      d5 = InstanceNormalization()(d5)\n",
        "\n",
        "      validity = Conv2D(1, kernel_size=4, strides=2, padding='same')(d5)\n",
        "      print(\"validityshape: \",validity.shape)\n",
        "\n",
        "      return Model(img, [validity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZow6dssZIdo"
      },
      "outputs": [],
      "source": [
        "class CycleGAN(CycleGAN):\n",
        "      def sample_images(self, epoch, batch_i):\n",
        "        r, c = 2, 3\n",
        "\n",
        "        imgs_A = self.data_loader.load_data(domain=\"A\", batch_size=1, is_testing=True)\n",
        "        imgs_B = self.data_loader.load_data(domain=\"B\", batch_size=1, is_testing=True)\n",
        "        \n",
        "        fake_B = self.g_AB.predict(imgs_A)\n",
        "        fake_A = self.g_BA.predict(imgs_B)\n",
        "\n",
        "        reconstr_A = self.g_BA.predict(fake_B)\n",
        "        reconstr_B = self.g_AB.predict(fake_A)\n",
        "\n",
        "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n",
        "\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        titles = ['Original', 'Translated', 'Reconstructed']\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt])\n",
        "                axs[i, j].set_title(titles[j])\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig('/content/drive/MyDrive/images3/%s/%d_%d.png' % (self.dataset_name, epoch, batch_i))\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Cywl7CgZKdq"
      },
      "outputs": [],
      "source": [
        "class CycleGAN(CycleGAN):\n",
        "      def train(self, epochs, batch_size=1, sample_interval=50):\n",
        "        valid = np.ones((batch_size,) + self.disc_patch)\n",
        "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
        "\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n",
        "\n",
        "                fake_B = self.g_AB.predict(imgs_A)\n",
        "                fake_A = self.g_BA.predict(imgs_B)\n",
        "\n",
        "                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n",
        "                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n",
        "                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
        "\n",
        "                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n",
        "                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n",
        "                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
        "\n",
        "                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
        "\n",
        "\n",
        "                g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n",
        "                                                      [valid, valid,\n",
        "                                                       imgs_A, imgs_B,\n",
        "                                                       imgs_A, imgs_B])\n",
        "\n",
        "                if batch_i % sample_interval == 0:\n",
        "                    self.sample_images(epoch, batch_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GSjZ-8axZPKz",
        "outputId": "d56fc5a2-1cd0-4903-e31a-0d567217b543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validityshape:  (None, 2, 2, 1)\n",
            "validityshape:  (None, 2, 2, 1)\n",
            "d0shape:  (None, 128, 128, 3)\n",
            "d1shape:  (None, 64, 64, 64)\n",
            "d2shape:  (None, 32, 32, 128)\n",
            "r1shape:  (None, 32, 32, 128)\n",
            "d3shape:  (None, 16, 16, 256)\n",
            "r2shape:  (None, 16, 16, 256)\n",
            "d4shape:  (None, 8, 8, 512)\n",
            "r3shape:  (None, 8, 8, 512)\n",
            "u1shape:  (None, 16, 16, 256)\n",
            "u1shape:  (None, 16, 16, 512)\n",
            "r4shape:  (None, 16, 16, 256)\n",
            "u2shape:  (None, 32, 32, 128)\n",
            "u2shape:  (None, 32, 32, 256)\n",
            "r5shape:  (None, 32, 32, 128)\n",
            "u3shape:  (None, 64, 64, 64)\n",
            "(None, 128, 128, 3)\n",
            "d0shape:  (None, 128, 128, 3)\n",
            "d1shape:  (None, 64, 64, 64)\n",
            "d2shape:  (None, 32, 32, 128)\n",
            "r1shape:  (None, 32, 32, 128)\n",
            "d3shape:  (None, 16, 16, 256)\n",
            "r2shape:  (None, 16, 16, 256)\n",
            "d4shape:  (None, 8, 8, 512)\n",
            "r3shape:  (None, 8, 8, 512)\n",
            "u1shape:  (None, 16, 16, 256)\n",
            "u1shape:  (None, 16, 16, 512)\n",
            "r4shape:  (None, 16, 16, 256)\n",
            "u2shape:  (None, 32, 32, 128)\n",
            "u2shape:  (None, 32, 32, 256)\n",
            "r5shape:  (None, 32, 32, 128)\n",
            "u3shape:  (None, 64, 64, 64)\n",
            "(None, 128, 128, 3)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-c3c1044e578c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcycle_gan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCycleGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcycle_gan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-109-b5b8ba52b63b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m     25\u001b[0m                                                       [valid, valid,\n\u001b[1;32m     26\u001b[0m                                                        \u001b[0mimgs_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs_B\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                                                        imgs_A, imgs_B])\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_i\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msample_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2091\u001b[0m                                                     class_weight)\n\u001b[1;32m   2092\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2093\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2095\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/model_48/model_47/conv2d_683/Conv2D_1/Conv2DBackpropInput' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 661, in <lambda>\n      self.io_loop.add_callback(lambda: self._handle_events(self.socket, 0))\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 577, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 606, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 556, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-110-c3c1044e578c>\", line 2, in <module>\n      cycle_gan.train(epochs=100, batch_size=64, sample_interval=10)\n    File \"<ipython-input-109-b5b8ba52b63b>\", line 27, in train\n      imgs_A, imgs_B])\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 2093, in train_on_batch\n      logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 863, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 531, in minimize\n      loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 583, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 464, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model_48/model_47/conv2d_683/Conv2D_1/Conv2DBackpropInput'\nOOM when allocating tensor with shape[64,64,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model_48/model_47/conv2d_683/Conv2D_1/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_407026]"
          ]
        }
      ],
      "source": [
        "cycle_gan = CycleGAN()\n",
        "cycle_gan.train(epochs=100, batch_size=64, sample_interval=10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "multiple residual bs, feature_loss",
      "provenance": [],
      "mount_file_id": "17awv-Pvyqmlo_DHrghOufKhhwAZBuMNV",
      "authorship_tag": "ABX9TyOvpAbbwWJy73J4JWlnRHTf",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}